{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6ab707-0e44-43dd-8698-50870cb3e190",
   "metadata": {},
   "source": [
    "## Collecting images using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14212ff2-8f98-4284-9268-abe0402df468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a829c8-7124-41a1-b8c4-dd45a97e4ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('b0f3fb66-4386-11ef-996e-04e8b9b51bf6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid.uuid1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b24da64-6313-4682-a5ff-1cc283c323ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_Path = os.path.join(\"data\",\"images\")\n",
    "number_images = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5196c9b3-aa8b-44c7-ac9e-7cae259c04a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting image: 0\n",
      "collecting image: 1\n",
      "collecting image: 2\n",
      "collecting image: 3\n",
      "collecting image: 4\n",
      "collecting image: 5\n",
      "collecting image: 6\n",
      "collecting image: 7\n",
      "collecting image: 8\n",
      "collecting image: 9\n",
      "collecting image: 10\n",
      "collecting image: 11\n",
      "collecting image: 12\n",
      "collecting image: 13\n",
      "collecting image: 14\n",
      "collecting image: 15\n",
      "collecting image: 16\n",
      "collecting image: 17\n",
      "collecting image: 18\n",
      "collecting image: 19\n",
      "collecting image: 20\n",
      "collecting image: 21\n",
      "collecting image: 22\n",
      "collecting image: 23\n",
      "collecting image: 24\n",
      "collecting image: 25\n",
      "collecting image: 26\n",
      "collecting image: 27\n",
      "collecting image: 28\n",
      "collecting image: 29\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "for i in range(number_images):\n",
    "    print(\"collecting image: \" + str(i))\n",
    "    ret, frame = cap.read()\n",
    "    imagename = os.path.join(Images_Path,f'{str(uuid.uuid1())}.jpg')\n",
    "    cv2.imwrite(imagename,frame)\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3eb3b-f725-4be5-b0fa-b054927d26e8",
   "metadata": {},
   "source": [
    "## Annotation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30519a0f-e92b-4921-b334-a8e9b5765b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 20:56:48,582 [INFO   ] __init__:get_config:67- Loading config file from: C:\\Users\\PMYLS\\.labelmerc\n"
     ]
    }
   ],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1217c226-93a2-4f26-8001-4feb0b01a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2813f3d2-5ec1-4ce2-bf05-604d06a34112",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6208a030-fded-45e1-b469-1288afba9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files('data\\\\images\\\\*.jpg',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3f91632-b54c-4d51-a8f6-b0a2eb765ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data\\\\images\\\\618df3d3-4387-11ef-a177-04e8b9b51bf6.jpg'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38ecf378-ef34-4447-8cf3-d08d5f490e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "    bytes = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(bytes)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8c4dfcd-9545-42e4-b7aa-d9cee616c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9d211f3-a18b-4f43-8ff2-b1b1744796a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterator = images.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adaf9bca-23ef-4142-95b7-7f57a31c6eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n",
      "valid\n"
     ]
    }
   ],
   "source": [
    "# Moving labels to correct subsets\n",
    "\n",
    "for folder in ['train','test','valid']:\n",
    "    print(folder)\n",
    "    for file in os.listdir(os.path.join(\"data\",folder,\"images\")):\n",
    "        filename = file.split(\".\")[0] + \".json\"\n",
    "        existing_path = os.path.join(\"data\",\"labels\",filename)\n",
    "        if os.path.exists(existing_path):\n",
    "            new_path = os.path.join(\"data\",folder,\"labels\",filename)\n",
    "            os.replace(existing_path,new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be7317f8-02eb-453f-a3fa-67e758cf0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20d1308e-fb13-4b55-9b08-10b7712dac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5a9aca5-476a-4642-a621-0ca91449d8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_max is less than or equal to x_min for bbox [0.3105244252873563, 0.004909003831417652, 0.0016163793103447955, 0.45270593869731807, 'face'].\n"
     ]
    }
   ],
   "source": [
    "for partition in ['train','test','valid']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [640,480,640,480]))\n",
    "\n",
    "        try: \n",
    "            for x in range(60):\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "\n",
    "\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8edae7a3-29d3-445c-bb67-53b88d75f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1020402e-8214-45fd-9fac-7ad7835f5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18372fd4-39d0-44fd-9df9-986f88717b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\valid\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(load_image)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "492f1e78-2c63-4cb7-997b-14c17be2e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']], label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99c7d554-4232-49f9-93c0-9395baf343b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c56cc38f-51e9-4df8-b898-866690fbe180",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a65df49c-07a2-45b0-bb02-deb6e47e4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\valid\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2a6579d-e40f-4e0e-9b28-bd4587e32e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_iter = train_images.as_numpy_iterator()\n",
    "train_lab_iter = train_labels.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e060c73-7c4e-457a-a2aa-4250221ebb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = train_img_iter.next()\n",
    "sample_lab = train_lab_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e88784d-a4fe-4ebe-8f2c-d18570d9ee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3720\n",
      "840\n",
      "780\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "print(len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4e59131-7ccd-4569-88f3-593ab71aa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(5000)\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58634842-dccf-49dc-8996-96252107c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(1300)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ccb6736b-bc2c-4acd-aaa0-88646cbdea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(1000)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e9fc7-3ce6-4762-984b-ac700b26f90b",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a13cbd-b580-4375-b8ae-196c273a3801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PMYLS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0583c882-8fe0-4137-add5-99d6b6329550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PMYLS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\PMYLS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7040fd5b-9d68-476a-ab25-cba5a47a6435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e71caa-bf8f-4ff0-900f-320280bc8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    input_layer = Input(shape=(120,120,3))\n",
    "    vgg = VGG16(include_top = False)(input_layer)\n",
    "\n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation = \"relu\")(f1)\n",
    "    class2 = Dense(1, activation = \"sigmoid\")(class1)\n",
    "\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation = \"relu\")(f2)\n",
    "    regress2 = Dense(4, activation = \"sigmoid\")(regress1)\n",
    "\n",
    "    return Model(inputs = input_layer, outputs = [class2,regress2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0efaf9-7909-472d-88ae-97045df7b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetracker = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67895304-8b08-46f4-a6e4-9097d4045634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 120, 120, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " vgg16 (Functional)          (None, None, None, 512)      1471468   ['input_2[0][0]']             \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      " global_max_pooling2d (Glob  (None, 512)                  0         ['vgg16[0][0]']               \n",
      " alMaxPooling2D)                                                                                  \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Gl  (None, 512)                  0         ['vgg16[0][0]']               \n",
      " obalMaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 2048)                 1050624   ['global_max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 2048)                 1050624   ['global_max_pooling2d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2049      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 4)                    8196      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16826181 (64.19 MB)\n",
      "Trainable params: 16826181 (64.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "facetracker.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5604d-55e7-4e10-a0b4-47298797683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c2d1bb21-4e81-4a1f-9c29-04cb136225f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train)\n",
    "lr_decay = (1./0.75 -1)/batches_per_epoch\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "53d1f80b-56ad-4c12-b770-9917e8e8cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):            \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] \n",
    "    w_true = y_true[:,2] - y_true[:,0] \n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "535af2c6-5abe-4d84-8f09-8dbd9485f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy()\n",
    "regressloss = localization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6d84be-9376-45bc-a15e-773d82f538a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTracker(Model):\n",
    "    def __init__(self,facetracker,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = facetracker\n",
    "\n",
    "    def compile(self,opt,classloss,regressloss,**kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.rloss = regressloss\n",
    "        self.opt = opt\n",
    "\n",
    "    def train_step(self,batch,**kwargs):\n",
    "\n",
    "        X,y = batch\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            classes, coords = self.model(X,training = True)\n",
    "            classloss = self.closs(y[0],classes)\n",
    "            regressloss = self.rloss(tf.cast(y[1],tf.float32),coords)\n",
    "\n",
    "            total_loss = regressloss + 0.5 * classloss\n",
    "\n",
    "            grad = tape.gradient(total_loss,self.model.trainable_variables)\n",
    "            opt.apply_gradients(zip(grad,self.model.trainable_variables))\n",
    "\n",
    "            return {\"total_loss\":total_loss, \"class_loss\":classloss, \"regress_loss\":regressloss}\n",
    "\n",
    "    def test_step(self,batch,**kwargs):\n",
    "\n",
    "        X,y = batch\n",
    "        \n",
    "        classes, coords = self.model(X,training = False)\n",
    "        classloss = self.closs(y[0],classes)\n",
    "        regressloss = self.rloss(tf.cast(y[1],tf.float32),coords)\n",
    "\n",
    "        total_loss = regressloss + 0.5 * classloss\n",
    "    \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":classloss, \"regress_loss\":regressloss}      \n",
    "            \n",
    "    def call(self,X,**kwargs):\n",
    "        return self.model(X,**kwargs)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "315cda5c-fa68-44b7-8217-5da369b6b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceTracker(facetracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09e947-4470-4bd9-8169-206706af1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt,classloss,regressloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6883117-ed89-46a1-98d0-970f86568a9d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6877784e-53d6-49f8-8df7-2df4d0eacfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d429a44a-04dd-4aa3-a4e8-3ba4e75185c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100369b-2c78-4061-a9a1-2a4a31622c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d749b52",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb6b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
